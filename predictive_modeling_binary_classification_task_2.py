# -*- coding: utf-8 -*-
"""Predictive Modeling-Binary Classification Task-2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nBjuqf-eYDolZqLsBLXW1QpD4RHFR2BV
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score,precision_score,roc_curve,roc_auc_score,recall_score,confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

df=pd.read_csv('/content/Heart Attack.csv')
df.head()

df.columns

x = df.drop(columns=['class'])
y = df['class'].apply(lambda x: 1 if x == 'positive' else 0)
print(x)
print(y)
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)
clf=DecisionTreeClassifier(random_state=42)
clf.fit(x_train,y_train)
y_pred=clf.predict(x_test)
for prediction in y_pred:
  if prediction == 1:
    print('positive')
  else:
      print('negative')
print(prediction)

accuracy = accuracy_score(y_test,y_pred)
precision = precision_score(y_test,y_pred)
recall = recall_score(y_test,y_pred)
print("Accuracy:{:.2f}".format(accuracy))
print("Precision:{:.2f}".format(precision))
print("Recall:{:.2f}".format(recall))

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', cbar=False)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

y_prob = clf.predict_proba(x_test)[:,1]
fpr, tpr, thresholds_roc = roc_curve(y_test, y_prob)
roc_auc = roc_auc_score(y_test, y_prob)

plt.figure(figsize=(6,4))
plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (AUC = %0.2f)' % auc)
plt.plot([0, 1], [0, 1], color='red', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

from sklearn.metrics import precision_recall_curve
import matplotlib.pyplot as plt

# Calculate precision-recall curve
precision, recall, _ = precision_recall_curve(y_test, y_prob)

# Calculate AUC for precision-recall curve manually
pr_auc = 0
for i in range(len(recall)-1):
    pr_auc += (recall[i+1] - recall[i]) * precision[i+1]

# Plot precision-recall curve
plt.figure(figsize=(8,6))
plt.plot(recall, precision, color='red', lw=2, label='Precision-Recall Curve (AUC = %0.2f)' % pr_auc)
plt.plot([0,1],[0,1],color='green', linestyle='dashdot')
plt.xlim([0.0,1.0])
plt.ylim([0.0,1.05])
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower right")
plt.grid(True)
plt.show()